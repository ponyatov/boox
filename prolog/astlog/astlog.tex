\secrel{ASTLOG: Язык для анализа синтаксических деревьев}\secdown
\cp{\url{http://www.cs.nyu.edu/~lharris/papers/crew.pdf}}
\copyright\ Roger F. Crew \email{rfc@microsoft.com}\\
Microsoft Research
Microsoft Corporation
Redmond, WA 98052

\secly{Abstract}

We desired a facility for locating/analyzing syntactic artifacts in abstract
syntax trees of \ci/\cpp\ programs, similar to the facility \prog{grep} or
\prog{awk} provides for locating artifacts at the lexical level. \prolog, with
its implicit pattern-matching and backtracking capabilities, is a natural choice
for such an application. We have developed a \prolog\ variant that avoids the
overhead of translating the source syntactic structures into the form of a
\prolog\ database; this is crucial to obtaining acceptable performance on large
programs. An interpreter for this language has been implemented and used find
various kinds of syntactic bugs and other questionable constructs in real
programs like \prog{Microsoft SQL server} (450Klines) and \prog{Microsoft Word}
(2Mlines) in time comparable to the runtime of the actual compiler.

The model in which terms are matched against an implicit current object, rather
than simply proven against a database of facts, leads to a distinct ``inside-out
functional'' programming style that is quite unlike typical \prolog, but one
that is, in fact, well-suited to the examination of trees. Also, various second-order
\prolog\ set-predicates may be implemented via manipulation of the current
object, thus retaining an important feature without entailing that the database
be dynamically extensible as the usual implementation does.

\secrel{Introduction}\secdown

Tools like \prog{grep} and \prog{awk} are useful for finding and analyzing
lexical artifacts; e.g., a one-line command locates all occurences of a
particular string. Unfortunately, many simple facts about programs are less
accessible at the character/token level, such as the locations of assignments to
a particular \cpp\ class member. In general, reliably extracting such syntactic
constructs requires writing a parser or some fragment thereof. And after writing
one's twenty-seventh parser fragment, one might begin to yearn for a more
general tool capable of operating at the syntax-tree level.

Even given a compiler front-end that exposes the abstract syntax tree (AST)
representation for a given program, there remains the question of what exactly
to do with it. To be sure, supplying a \ci\ programmer with a sufficiently
complete interface to this representation generally solves any problem one might
care to pose about it. One may just as easily say that all problems at the
lexical level may be solved via proper use of the UNIX standard IO library
\verb|<stdio.h>|, a true, but utterly trivial and unsatisfying statement. The
question is rather that of building a simpler, more useful and flexible
interface: one that is less error-prone, more concise than writing in \ci, and
more directly suited to the task of exploring ASTs. We first consider a couple
of prior approaches.

\secrel{The \prog{awk} Approach}

One of the more popular approaches is to extend the \prog{awk} \cite{AKW86}
paradigm. An \prog{awk} script is a list of pairs, each being a
regular-expression with an accompanying statement in a C-like imperative
language. For each line in the input file, we consider each pair of the script
in turn; if the regular-expression matches the line, the corresponding statement
is executed.

Extending this to the AST domain is straightforward, though with numerous
variations. One defines a regular-expression-like language in which to express
tree patterns and an \prog{awk}-like imperative language for statements. The
tree nodes of the input program are traversed in some order (e.g., preorder),
and for each node the various pairs of the script are considered as before.

We have two objections to this approach, the first having to do with the
hardwired framework that usually implicit. In some cases (e. g., \prog{TAWK}
\cite{GA96}), the traversal order for the AST nodes is essentially fixed; using
a different order would be analogous to attempting to use plain \prog{awk} to
scan the lines of a text file in reverse order. In $A*$ \cite{LR95}, while the
user may define a general traversal order, only one traversal method may be
defined/active at any given time, making difficult any structure comparisons
between subtrees or other applications that require multiple concurrent
traversals. Since the imperative language is quite general in both cases, little
is deffinitively impossible, however for some applications one may be little
better off than when programming in straight \ci.

The second objection has to do with the kinds of pattern-abstraction available.
Inevitably there exist simply-described patterns that are a poor fit to a
regular-expression-like syntax. This tends to happen when said simple
descriptions are in terms of the idioms of a particular programming language;
most of the various tree-\prog{awk} pattern languages tend to be designed with
the intent of being language independent.

Suppose one wishes to find all consecutive occurrences of one statement
immediately preceding another, e. g., places where a given system call
\verb|syscall();| is followed immediately by an \verb|assert();| \note{on the
theory that testing of outcomes of system calls should be done in production
code rather than just debugging code}. A tree-regular-expression pattern of the
form

\begin{verbatim}
<syscall() pattern>; <assert() pattern>
\end{verbatim}

\noindent
(where \verb|;| is the regular-expression sequence operator) finds all instances
of the two calls occurring consecutively within a single block, but it misses
instances like

\begin{verbatim}
syscall();
{
    assert();
    ...
}
\end{verbatim}

and

\begin{verbatim}
if (...) {
    syscall();
}
else {
    ...
}
assert();
\end{verbatim}

While the tree-\prog{awk} languages allow one to write patterns to match each of
these cases, without a pattern-abstraction facility, we may be back at square
one when it comes time to look for some \emph{different} pair of consecutive
function calls. We prefer to write a single consecutive-statement pattern
constructor \emph{once} and then be able to use it for a variety of cases where
we need to find pairs of consecutive statements satisfying certain criteria,
invoking it as

\begin{verbatim}
follow_stmt(<syscall() pattern>, <assert() pattern>)
\end{verbatim}
for the above problem, or, if we instead want to be fiding all of the places
where a \ci\ switch-case falls through, as
\begin{verbatim}
follow_stmt(not(<unconditional-jump pattern>),
                <case-labeled stmt pattern>)
\end{verbatim}

One solution, used by \prog{TAWK}, is to use \prog{cpp}, the C preprocessor, to
preprocess the script, allowing for pattern-abstractions to be expressed as
\verb|#define| macros whose invocations are then expanded as needed. This is
unsatisfactory in a number of ways, whether one wants to consider the problem of
recursively-defined patterns, macros with large bodies that result in a
corresponding blow-up in the size of the script, or the difficulty of tracing
script errors that resulted from complex macro-expansions.

Another way out is to fall back on the procedural abstraction available in the
imperative language that the patterns invoke. One essentially uses a degenerate
pattern that always matches and then allows the imperative code to test whether
the given node is in fact the desired match, defining functions to test for
particular patterns. Once again, it seems we are back to programming in straight
C and not deriving as much benefit from having a pattern language available as
we could be.

In general, the philosophical underpinning of the \prog{awk} approach is that
the designer has already determined the kinds of searches the user will want to
do; the effort is put towards making those particular searches run efficiently.
There is also an assumption that the underlying imperative language for the
actions has all the abstraction facilities one will ever need, so that if the
pattern language is lacking in various ways, this is not deemed a serious
problem. While this is not an unreasonable approach, we have less confidence of
having identified all of the reasonable search possibilities, and thus would
prefer instead to make the pattern language more flexible and extensible, being
willing to sacrifice some efficiency to do so.

\secrel{The Logic Programming Approach}

Another common approach is to run an inference engine over a database of program
syntactic structures \cite{BCD88, BGV90, CMR92}. \prolog\ \cite{SS86} is a
convenient language for this sort of application. Backtracking and a form of
pattern matching are built in, the abstraction mechanisms to build up complex
predicates exist at a fundamental level, andfinally, \prolog\ allows for a more
declarative programming style.

The problems with using \prolog\ are two-fold. First there is the issue of
efficiency. Second, we must represent the AST for our source program in the
\prolog\ database. Large programs ($10^5..10^6$ lines) will result in
correspondingly large \prolog\ databases, most likely with a significant
performance penalty.

We finesse the second problem by not attempting to import the source program's
AST at all, instead opting to modify the interpretation of the predicates and
queries of \prolog\ so as to be applicable to external objects rather than just
facts provable in the existing database. Removing reasons that require the
database to grow beyond the initial script creates significant opportunities for
optimization. This, however, requires removing primitives like \verb|assert()|
and \verb|retract()| that allow for the dynamic (re)defiition or removal of
predicates, which in turn removes many higher-order logical features that are
defined in terms of them. Fortunately, some of the more essential ones can be
restored at relatively little cost.

\secup

\secrel{Elements of ASTLOG}\secdown

Section \ref{crewsyntax} gives the complete syntax for our language, ASTLOG. The
ASTLOG interpreter reads a script of user-defined predicate operator definitions
and then runs one or more queries.

As in \prolog, the definition of a user-defined predicate operator is composed
of one or more \term{clauses}. A compound term \verb|opname(term,...)| appearing
at top level in a clause body is interpreted as a predicate, whether
\term{opname} be primitive or user-defined. In the latter case, the script is
searched for a defining clause whose head terms successfully unify with the
respective operand terms of the given compound term, variables are bound
accordingly, and the terms of the clause body are likewise interpreted. The
clause \emph{succeeds} (i. e., is found to be true) if all of its body terms
succeed. Whenever a clause head fails to unify, or a clause body term
\emph{fails} (i. e., is found to be false), or any primitive term fails by the
rules of evaluation of that primitive, we backtrack to the last point where
there was a choice (e. g., of clauses to try for a given compound term) and
continue.

A \term{query} is a clause whose head terms are all variables. Ultimately,
whenever all terms of a query body succeed, the bindings of any variables listed
in the query head (\term{qhead}) are reported. Otherwise, we report failure.
Thus far, this is all exactly like \prolog.

\subsecly{Figure 1: Complete Syntax of ASTLOG}\label{crewsyntax} 

\begin{tabular}{l l l}
script & ::= named-clause* & script file syntax \\
query & ::= imports? ( varname* ) clause-body ; & query syntax \\
imports & ::= \{ varname+ \} &\\
named-clause & ::= opname anon-clause &\\
anon-clause & ::= ( term* ) clause-body? ; &\\
clause-body & ::= <- term+ &\\
\end{tabular}

\noindent
\begin{tabular}{l l l}
\hline
&Essential Term Syntax&\\
\hline
term & ::= literal & reference to denotable ob ject \\
& ::= varname &\\
& ::= opname ( term* ) & compound term \\
& ::= FN imports? ( anon-clause+ ) & anonymous predicate-operator-valued 
\\&&(``lambda'') term \\
& ::= ' opname arity-spec? & named predicate-operator-valued
\\&&(``function quote'') term \\
& ::= ( term )( term* ) & ``application'' term \\ 
\end{tabular}

\noindent
\begin{tabular}{l l l}
\hline
&Gratuitous Term Syntax&\\
\hline
&::= \# constname & named constant\\&&($\equiv$ corresponding literal number)\\
&::= \verb|[ term* ]| & \verb|[ ]| $\equiv$ nil(), \verb|[term]| $\equiv$
cons(term; nil()), etc\ldots\\
&::= \verb$[ term+ | term ]$ & \verb$[ term1 | term2 ]$ $\equiv$
cons(term1,term2), etc\ldots\\
arity-spec & ::= / integer &\\ 
\end{tabular}

\secrel{Objects}

ASTLOG refers to external objects. Given a \ci/\cpp\ compiler front end that
provides a (\cpp) interface to the syntactic/semantic data structures built
during the parse of a given program, it is simple to graft this onto the core of
ASTLOG so that it may recognize object references corresponding to
\begin{itemize}[nosep]
  \item whole C/C++ programs,
  \item single files,
  \item symbols,
  \item AST nodes (including statements, expressions, and declarations), and
  \item \ci/\cpp\ type descriptions.
\end{itemize}

For the purposes of ASTLOG, an \term{object} is simply some external entity that
is significant for its identity and for the primitive predicates that it may
satisfy. To simplify the language we regard the traditional
constants (integers, floats, and strings) to be references to ``external''
objects as well, though one could just as easily take the converse view in which
the universe of object references is just a (very large) pool of
constants\note{``atoms'' in the usual \prolog\ terminology}.

In any case, object references are terms in ASTLOG. Only references to equal
objects can unify, equality meaning numeric equality for numbers,
same-sequence-of-characters for strings, and identity for all other classes of
objects. Only objects that have denotations (numbers, strings and the unique
\verb|null object*|) can find their way into scripts.

\secrel{The Current Object}

The first significant departure from the \prolog\ model is that a query or
predicate term always evaluates under an ambient \term{current object}. Every
query and every term being evaluated as a predicate is not so much a standalone
statement that may or may not be intrinsically true (i. e., provable from the
``facts'' in the script) as it is a specification that may or may not be
satisfied by the current ob ject, or, alternatively, a \term{pattern} that may
or may not \term{match} the current object. For example, in \prolog
\begin{verbatim}
odd(3)
\end{verbatim}
always succeeds by virtue of 3 being odd or because the ``fact'' \verb|odd(3)|
exists in the script somewhere. By contrast, in ASTLOG
\begin{verbatim}
odd()
\end{verbatim}
succeeds if the current object happens to be the integer 3, fails if the current
object is 4, and raises an error if the current object is the string
\verb|"Hi mom"|. Another way to view this is that every predicate term takes an
extra, hidden current-object operand.

While one normally only expects to see compound (and application) terms in
predicate position, ASTLOG allows variables and ob ject references there as
well. The rules for matching are as follows:

\begin{itemize}
  \item 
An object reference matches the current object, if it references an equal
object.
  \item 
A bound variable matches according as whatever term it is bound to.
  \item 
An unbound variable gets bound to reference the current ob ject (and thus
automatically matches it).
\item 
A compound term whose operator is defined via clauses matches if there exists a
clause whose head operands unify with the term operands and whose body terms
themselves all match the current object.
\end{itemize}

Section \ref{crew31} describes the operator-valued and application terms.

The evaluation rules for compound terms having primitive operators are widely
varied, however the operands are usually treated one of two ways:

\begin{enumerate}
  \item 
\verb|(foo-pred)| requiring the operand to be match some object\note{which
becomes the current object for that evaluation}, not necessarily the same
current object as that which the full term is being matched against. For
example, the operand of \verb|strlen| (see \ref{crewfig2}) and the second
operand of \verb|with| are treated this way.
  \item 
\verb|(foo)| requiring the operand be an object reference, whether this be a
literal or an object-reference-bound variable. The operands of \verb|re|,
\verb|gt|, and the first operand of \verb|with| are treated this way.
\end{enumerate}

Most primitives also expect a current ob ject to be of a particular kind and
raise an error if confronted with something different.

The use of an implicit current object is not by itself an increase in
expressivity. If we had, in a \prolog\ database, terms representing the various
AST nodes, there would be a fairly straightforward translation of ASTLOG terms
into \prolog\ terms, one in which we simply modify all terms to make the current
object an explicit operand.

Nevertheless, ASTLOG programs exhibit a distinct style of programming. Consider
as an example that we might, in a typical functional language, write a function
call
\begin{verbatim}
strlen(string)
\end{verbatim}
to find the length of the string returned by the expression \verb|string|. Here
the length result is implicitly returned to the context of the call. In \prolog,
the natural style would be to express this as a relation
\begin{verbatim}
strlen(string, length)
\end{verbatim}
which stipulates that \verb|length| is in fact the length of \verb|string|. In
ASTLOG, we would write
\begin{verbatim}
strlen(length-pred)
\end{verbatim}
where now it is the \verb|string| argument that is implicitly supplied \emph{as
the current object} \textit{by} the context while the length result is returned
\textit{to} the subterm \verb|length-pred|, which in turn can be some arbitrary
term expecting a numeric current ob ject as its implicit argument. For example,
given an \verb|odd()| predicate as above, the term \verb|strlen(odd())| would
match any string consisting of an odd number of characters. It is this
``inside-out functional'' evaluation strategy that makes ASTLOG well-suited to
constructing anchored patterns to match tree-like structures.

\subsecly{Figure 2: Some core ASTLOG primitives}\label{crewfig2}

\begin{itemize}
  \item 
\verb|and(object-pred,... )|\\
The current object satisfies every \verb|object-pred| operand. 
  \item 
\verb|or(object-pred,... )|\\
The current object satisfies some \verb|object-pred| operand. 
  \item 
\verb|if(object-pred, then-pred, else-pred)|\\
The current object satisfies \verb|then-pred| or \verb|else-pred| according as
it satisfies or fails to satisfy \verb|object-pred| (once; if \verb|object-pred|
matches but \verb|then-pred| does not, we do not retry \verb|object-pred|). 
  \item 
\verb|not(object-pred)|\\
\verb|= if(object-pred, or(), and())|
  \item 
\verb|with(object, object-pred)|\\
\verb|object| satisfies \verb|object-pred| (outer current object is ignored).
  \item 
\verb|strlen(integer-pred)|\\
The current string object has length satisfying \verb|integer-pred|. 
  \item 
\verb|re(string)|\\
The regular expression \verb|string| matches the current string. 
  \item 
\verb|gt(integer)|\\
The current integer is greater than \verb|integer|. 
  \item 
\verb|minus(integer-pred, integer)|\\
\verb|integer-pred| matches the current integer \verb|+ integer|. 
  \item 
\verb|minus(integer, integer-pred)|\\
\verb|integer-pred| matches \verb|integer|\ --- the current integer.\\
(An error is raised if neither operand of a minus term
is an integer ob ject reference.) 
  \item 
\verb|plus(integer-pred, integer)|\\
\verb|integer-pred| matches the current integer\ --- \verb|integer|

\subsecly{Figure 3: Some primitive node and symbol predicates}
  \item 
\verb|parent(ast-pred)|\\
This AST node is not a root node and its parent satisfies \verb|ast-pred|.
  \item 
\verb|kid(integer-pred; ast-pred)|\\
This AST node has a child satisfying \verb|ast-pred| whose (0-based) index
satisfies \verb|integer-pred|.
  \item 
\verb|kidcount(integer-pred)|\\
The number of children of this AST node satifies \verb|integer-pred|. 
  \item 
\verb|op(integer-pred)|\\
The opcode of this AST node satisfies \verb|integer-pred|. 
  \item 
\verb|atype(type-pred)|\\
This AST node has a return type satisfying \verb|type-pred|. 
  \item 
\verb|asym(symbol-pred)|\\
This AST node is a symbol satisfying \verb|symbol-pred|. 
  \item 
\verb|aconst(const-pred)|\\
This AST node is a constant (integer, float or string) satisfying
\verb|const-pred|.
  \item 
\verb|sname(string-pred)|\\
This symbol's name satisfies \verb|string-pred|. 
\end{itemize}

There are named constants available for designating the opcodes of various kinds
of nodes for use in \verb|op()| terms, and the indices of particular children
for use in \verb|kid()|.

\secrel{Examples}

Given the set of AST node primitives in Figure 3, we could write
\begin{verbatim}
and(op(#=), kid(#LEFT, asym(sname("foo"))))
\end{verbatim}
which would be satisified by any AST node that is an assignment (=) expression
whose left-hand side is itself a symbol expression where the symbol name is
"foo". Here, \verb|#=| and \verb|#LEFT| are numeric literals for the assignment
node opcode and the assignment target's childindex, respectively.

To define a predicate \verb|assignment/2| to match assignment nodes, a script
could include the clause
\begin{verbatim}
assignment(target, value)
    <- op(#=),
        kid(#LEFT, target),
        kid(#RIGHT, value);
\end{verbatim}
which would then allow writing the previous term as
\begin{verbatim}
assignment(asym(sname("foo")), _)
\end{verbatim}

As in \prolog, the underscore \verb|(_)| is ``wild-card'' variable, i.e., one
that is internally given a distinct identity so as not to be conated with any
other instances of \verb|_|. Such a variable, being guaranteed to be unbound,
will match any o ject or unify with any term.

Defining a general purpose node-traversal predicate is also straightforward
\begin{verbatim}
somenode(pred)
    <- or(pred, kid(_ , somenode(pred)));
\end{verbatim}
Given this definition, an attempt to match \verb|somenode(test)| to a given node
will create an instance of the defining clause of \verb|somenode/1| above with
pred bound to \verb|test|. Satisfying the clause body requires that either
\verb|pred| match the current node, or, if (when) that fails, that
\verb|kid(_,somenode(pred))| match the current node. The latter in turn will
attempt to match the variable \verb|_| with 0 (easy) and the term
\verb|somenode(pred)| with the first child, and, when that fails, \verb|_| with
1 and \verb|somenode(pred)| with the second child, etc\ldots Making the
interpreter fail and backtrack after each hit (in the usual manner of \prolog)
eventually causes \verb|test| to be matched with the original node and all of
its descendants.

So, if we issue the query
\begin{verbatim}
(v) <- somenode(
    assignment(asym(sname("foo")), v)
        );
\end{verbatim}
on the root node of some function's AST, we obtain, via the successive bindings
reported for \verb|v| on each hit, all of the expressions assigned to variables
named \var{"foo"} within that function.

As an example that makes less trivial use of backtracking, consider the problem
of whether two trees have the same structure (i.e., root nodes have the same
opcode and all corresponding children have the same structure).
\begin{verbatim}
sametree(node)
    <- op(nodeop),
       with(node, op(nodeop)),
       not(and(with(node, kid(n, nkid)),
           kid(n, not(sametree(nkid)))));
\end{verbatim}

This defines a predicate \verb|sametree(node)| that holds if \verb|node| is a
reference to an AST node with the same structure as the current object. The
first line of the clause body binds the current node's opcode to \verb|nodeop|,
the second line compares that to the opcode of \verb|node|, while the remaining
lines search for children whose subtrees have distinct structure. The term
\verb|kid(n, nkid)| will match each child of \verb|node|, since both variables
are initially unbound. If \verb|sametree(nkid)| happens to be true of the
corresponding child of the current node, the inner \verb|not| fails and we go
back and try another child of \verb|node|. If \verb|sametree(nkid)| happens to
be true of \emph{every} corresponding child of the current node, then the
enclosing \verb|not| and thus the outer \verb|sametree(node)| invocation
succeeds.

The preceding version of \verb|sametree/1| is a purely
structural comparison; there is no attempt to take account
of the commutativity/associativity of the various
operators, e. g., \verb|a + b| and \verb|b + a| are not considered
the same. If, say, we \emph{did} want to consider commutativity,
we could define
\begin{verbatim}
csametree(node)
    <- op(nodeop),
       with(node,op(nodeop)),
       kidcount(if(with(nodeop,commutes()),
                    any_perm(perm),
                    id_perm(perm))),
       not(and(with(node,kid(corresp(perm,n),
                            nkid)),
                kid(n,not(csametree(nkid)))));
\end{verbatim}
along with suitable definitions of
\begin{description}
\item[commutes()]\ \\
the current integer is the opcode of a commutative operator,
\item[any\_perm(perm)]\ \\
\verb|perm| is any permutation of the sequence\\
\verb|0, ... , (<current-object> - 1)|,
\item[id\_perm(perm)]\ \\
\verb|perm| is the identity permutation of the sequence\\
\verb|0, ... , (<current-object> - 1)|,
\item[corresp(perm, n)]\ \\
permutation \verb|perm| takes the current integer to something matching
\verb|n|.
\end{description}
Here, permutations can be represented by list terms. Note that since all of the
commutative \ci/\cpp operators are, in fact, binary, this all simplifies
significantly.

It should, incidentally, be clear that there is nothing about the core language
that is specifically tailored for the examination of compiler-produced ASTs, let
alone ASTs for a given language. The language in fact lends itself to the
examination of a wide variety of external structures, e. g., hierarchical file
systems, or collections of web pages. All that is needed is a suitable
collection of primitive ASTLOG predicates for querying said structures.

\subsecly{Figure 4: Actual ASTLOG code for follow\_stmt}

Actual ASTLOG code for \verb|follow_stmt| and how one uses it to find case
statement fallthroughs. The cond operator is an if-then-elseif- construct, that
is, \verb|cond(p1, e1, p2, e2,..., e)| is equivalent to
\verb|if(p1, e1,if(p2,e2,..,e))|. \verb|sfa(emit(string))| always succeeds and,
as a side-effect, emits the source location of the current AST node in
grep-output form.

\lstx{\file{follow\_stmt.astlog}}{prolog/astlog/follow.pl}

\subsecly{Figure 5: Definition of \file{flatten}}

\begin{verbatim}
flatten(test, lst)
  <- flatten(test, lst, []);

flatten(test, head, tail)
  <- if(test,
        first(head, hrest),
        unify(head, hrest)),
     flattenkids(test, 0, hrest, tail);

flattenkids(test, n, head, tail)
  <- if(kid(n, flatten(test, head, mid)),
        and(with(n, minus(nplus1,1)),
            flattenkids(test, nplus1,
                        mid, tail)),
        unify(head, tail));

first([o|rest],rest) <- o;
unify(x,x);
\end{verbatim}

\subsecly{Figure 6: Parameterized version, \file{flatten2}}

\begin{verbatim}
flatten2(test, lst)
  <- flatten2(test, lst, []);

flatten2(test, head, tail)
  <- if((test)(value),
        unify(head, [value|hrest]),
        unify(head, hrest)),
     flatten2kids(test, 0, hrest, tail);

flatten2kids(test, n, head, tail)
  <- if(kid(n, flatten2(test, head, mid)),
        and(with(n, minus(nplus1,1)),
            flatten2kids(test, nplus1,
                         mid, tail)),
        unify(head, tail));

unify(x,x);
\end{verbatim}



\secup

\secrel{}\secdown
\secrel{3.1}\label{crew31}
\secup

\secup