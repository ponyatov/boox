\secrel{GRAMMAR PROPERTIES }\label{cohen5}

This section makes extensive use of the built-in predicate setof which implicitly
relies on the nondeterministic capabilities of Prolog. In our view the use of this
and similar predicates in determining grammar properties is perfectly justifiable,
since, in this context, efficiency plays a secondary role: grammar properties are 
usually determined only a few of times when generating the parser and, although
it is important that the generated parser itself be efficient (and deterministic),
longer generation times are usually tolerable. 

We start by pointing out that it is easy to test whether a grammar is strictly
weak-precedence or LL(l), provided one knows the sets first(N), follow(N), and
last(N). The Prolog procedures for performing these tests follow the declarative
definitions closely and appear at the end of this section. We first show how
Prolog can be used to calculate these sets in the general case of context-free
grammars which may contain left-recursive nonterminals and e-rules. 

We assume that the rules for a grammar are stored in the database by assertions
like
\[rule(RuleNum, n(A), Rhs)\]
in which RuleNum is an integer number identifying a rule, Rhs is the list
representing the right-hand side of the rule defining the nonterminal A. Recall
that the elements of Rhs are identified by the terms of the form t(T) and n(N)
representing terminals and nonterminals. 

For each nonterminal N in the grammar, first(N) is the set of all (terminal or
nonterminal) symbols V such that N a* V . . . . To calculate the set first(A) for
a nonterminal A, we use the built-in procedure setof in conjunction with a
procedure first which finds a single element of this set. Thus, we make the toplevel
call:
\[allfirst(N, L) :- setof(X, first(N, [ 1, X), L).\]
The procedure \verb|first(Input, &a&, V)| has three parameters:

(1) an Input list representing a sequence (Y of terminals and/or nonterminals,

(2) a Stuck of rule numbers which keeps track of the already considered rules,

(3) a terminal or nonterminal element V such that (Y =J* V . . . .

There are three ways in which a symbol T can be the first element of a
sentential form derived from (Y: (1) it can be the first element of (Y, (2) it can be
the first element of a sentential form obtained by rewriting the first element in
cu (which must be a nonterminal in this case), or (3) it can be the first element
of a sentential form obtained by rewriting some of the initial nonterminals of (Y
into the empty string t. The following procedure contains a clause for each of
these three cases. The middle parameter \verb|&a&| is used to prevent looping by
prohibiting the consideration of previously used rules. The third clause uses the
procedure reduces-to-epsilon (defined below) to determine if a sequence of
nonterminals rewrites into 6 
\begin{verbatim}
first([Symbol 1 Rest], Stack, Symbol).
first([n(N) 1 Rest], Stack, Symbol) :-
rule(Number, n(N), Rks),
not(member(Number, Stack)),
first(Rks, [Number 1 Stuck], Symbol).
first(List, Stack, Symbol) :-
append(A, B, List),
Af[l,
reduces-to-epsilon(A),
first@, Stuck, Symbol). 
\end{verbatim}   
The predicate reduces-to-epsilon(A) will succeed if A represents a sequence cu of
nonterminals which rewrite into the empty string. If a sentential form reduces
to epsilon, then it must consist entirely of nonterminals that reduce to epsilon.
Moreover, if a nonterminal rewrites to epsilon, then there is a parse tree
representing this reduction such that no branch of the parse tree contains more
than one occurrence of any nonterminal. The translation of these two statements
into Prolog is straightforward. The procedure list-reduces-to-epsilon asserts that
a sequence of nonterminals List rewrites into epsilon if each of the nonterminals
does, and the procedure nt-reduces-to-epsilon asserts that a nonterminal N
reduces to epsilon if it rewrites into a sentential form that reduces to epsilon.
The stack parameter is used to guarantee that no branch of the parse tree
contains multiple occurrences of any nonterminal. 
\begin{verbatim}
reduces-to-epsilon(List) :-
list-reduces-to-epsilon(List, [ I).
list-reduces-to-epsilon([ 1, Stock).
list-reduces-to-epsilon([n(N) 1 Rest], Stack) :-
nt-reduces-to-epsih(n(N), [n(N) 1 Stack]),
list-reduces-to-epsilon(Rest, Stack).
nt-reduces-to-epsih(n(N), Stack) :-
rule(Number, n(N), Rhs),
not(intersect(Rhs, Stuck)),
list-reduces-to-epsilon(Rhs, Stack).
intersect(List1, L&2) :- member(X, L&l), member(X, L&2). 
\end{verbatim}
In weak-precedence, parsing reductions are called for when S > IV, where

(1) W is the terminal element in the window,

(2) S is the (terminal or nonterminal) element in the top of the stack,

(3) S > W if there exists a grammar rule

\[Y-a **- x,x,...,\]
where Xl ++ - - - S and WE first(Xz). 

Shifting occurs when S c W, that is, if there is a rule
\[Y-* *** sx, . . . . where W E first(X*).\]
To determine whether a language is of the weak-precedence type and to construct
the parsing tables, one needs to find for each nonterminal X the set last+(X),
consisting of all terminals and nonterminals V such that X J+ . . . V. This can
be done by finding the sets first(X) for the grammar that is obtained by reversing
the right-hand sides of the rules in the original grammar. It is easy to define a
procedure first-rev that finds the sets first(A) for the reversed grammar by
modifying the procedure first. The procedure to compute k\&+(A) is then
concisely expressed as follows:
\begin{verbatim}
lost-ph(n(X), 2) :-
rule(Number, n(X), Rhs),
reverse(Rhs, RRhs),
first-rev(RRhs, [ 1, Z).  
\end{verbatim}
As before, the set last+(A) can then be found using the setof predicate:
\[aUo.st-ph(n(A), L) :- setof(X, last-plus(n(A), [ 1, X), L).\]

The set follow(N) is also succinctly expressed in Prolog. There are two ways
in which a symbol V can be in the set follow(N): (1) there is a rule X --* \&V/3
such that V E first(@), or (2) there is a rule X + OlNp such that B rewrites into
epsilon, and V E follow(X). The Prolog procedure for follow consists of two
clauses closely paralleling these two cases. The middle parameter \verb|&a&| is
again used to prevent looping by prohibiting the multiple use of rules:
\begin{verbatim}
follow(n(N), Stack, Terminal) :-
rule(Number, n(X), Rhs),
not(member(Number, Stack)),
wwW& In(N) I Bl, Rh),
first(B, [ 1, Terminal).
follow(n(N), Stack, Terminal) :-
rule(Number, n(X), Rhs),
not(member(Number, Stack)),
~PP=U, [n(N) I Bl, Rh),
reduces-to-epsilon(B),
follow(n(X), [Number 1 Stack], Terminal).  
\end{verbatim}
The predicate all-follow below calculates the list of all follow symbols of a
nonterminal N:
\[all-follow(N, L) :- setof(X, follow(N, [ 1, X), L).\]
To assess the gains in program size and readability the reader may want to
compare the above programs with the English description of first and follow in
[l, p. 184] and with a Pascal version in [2]. As to efficiency, these programs
could be significantly improved by using the assert procedure to memorize previously
computed firsts and follows, thereby avoiding recomputation. (This technique,
called memoization, has been considered in [ 24].)  

The predicates first and follow and lust-plus can be used to test for the LL(1)
and weak-precedence grammar properties and to generate the parsing tables for
each of these types of grammars. For example, the clauses of the try\_reduce
procedure can be computed by the following procedure:
\begin{verbatim}
generate-reduces(L) :-
setof(try-reduce(X, Y), wp-greater(X, Y), L).
wp-greater(X, Y) :-
rule(RuleNum, n(N), Rhs),
appe~(Awl, [A, B I AnyPI, Rh),
last-plus(A, X),
first([B], Y). 
\end{verbatim}
and the try\_shift clauses can be generated in a similar manner. Once these
clauses have been computed and stored in the database, the grammar can be tested for
weak-precedence by the query:
\begin{verbatim}
not-weak-precedence :- try-reduce(S, W), try-shift(S, W).
not-weak-precedence :- rule(N, X, Rhs), rule(M, Y, Rhs), N # M 
\end{verbatim}
The first clause tests for reduce-shift conflicts, which could easily be reported to
the user for selecting the desired action. This choice enables the processing of
ambiguous grammars. The second clause tests if two grammar rules have identical
right-hand sides. 

The procedures to generate LL(1) tables and to test whether a grammar is
LL(1) can also be written concisely. The procedure that generates the tables
consists of a call to setof, combined with a procedure to find the firsts and follows
of the right-hand side of a rule:
\begin{verbatim}
generate-ill-table(L) :-
setof(entry(t(W), n(X), Rh), first-of-ruk(t(W), n(X), Rh), L).
first-of-r&( W, N, Rh) :-
ruk(Number, N, Rhs),
first(Rhs, W).
first-of-r&( W, N, Rhs) :-
rule(Number, N, Rh),
reduces-to-epsilon(Rhs),
follow(N, W). 
\end{verbatim}
To test whether a language is LL(1) we must show that the table constructed
above has no multiple entries. This can be done with a call to the procedure
\begin{verbatim}
n&-111, defined as follows:
not-ill :- entry(t( W), n(X), Rhsl), entry(t( W), n(X), Rhs2), Rhl # RhsP.
\end{verbatim}

The generation of the unit clauses for weak-precedence and LL(1) parsing
actually amounts to prototyping a parser generator. Additional discussion on this
topic is given in Section 6. The predicates first and last can also be used to
determine if a grammar contains a nonterminal that is left-recursive and also
right-recursive. This is a commonly used test for attempting to detect ambiguity
in context-free grammars. 

There is a host of grammar properties and transformations that could be
succinctly described in Prolog. A few that we have programmed are elimination
oft rules, general replacement of left-recursive rules by right-recursive ones, and
reduction to Chomsky and standard normal forms. Other properties that seem
likely candidates for description in Prolog are an attempt to determine if a
grammar is LL(k) or LR(k), and the reduction of an LR(K) grammar to LR(l). 

