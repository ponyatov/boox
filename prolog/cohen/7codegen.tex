\secrel{CODE GENERATION }\label{cohen7}\secdown

\secrel{Generating Code from Polish }

We start by describing a simple program that generates code for a single register
computer having the usual arithmetic operations, as well as the LOAD Vur and
STORE VW instructions, where Vur is the location of a variable. The DCG for
performing the translation is basically that used to generate the postfixed Polish
described in Section 4. The algorithm essentially operates as follows:

(1) When a variable is recognized it is placed on a stack.

(2) When an operation is recognized its two operands are on the top of the stack.
If these are variables the following instructions are generated:
\[LOAD 1st operand\]
\[Operation 2nd operand\]

Step (2) is continued by replacing the top elements of the stack with the mark
ccc to indicate that, at execution time, the result will be in the accumulator. To
take into account this mark we introduce the revised versions of (1) and (2),
which handle the cases where one of the operands is an occ mark.

(la) Before pushing a variable onto the stack it is necessary to check if the mark
ccc occupies the position just below the top of the stack. This indicates the
need of a temporary storage, since the accumulator was already utilized in
a previous operation and it contains a result that should not be destroyed.
Thus the mark act is replaced by Ti, the ith element of a pool of temporary
locations, and the following instruction is generated: ST0 Tie It is then
possible to push the recognized variable onto the stack.

(lb) If the penultimate element in the stack is not ccc, the variable is simply
pushed onto the stack.  

As for operators, two cases need to be considered: one for commutative
operations, the other for noncommutative ones. Let Sl be the top of the stack
and S2 the element just below it.

(2a) If neither Sl, nor S2 is an act, then code is generated as in step (2) above.

(2b, c) For the commutative operations (addition and multiplication) it suffices
to generate
Operation Sl if S2 is an ccc, or to generate
Operation S2 if Sl is an occ.

(2d) Noncommutative operations (subtraction and division) will check if Sl
is an act, in which case the instruction ST0 Ti has to be generated and
the stack updated with Ti instead of ccc, as is done in (la). The generation
proceeds as indicated in (2). The case where S2 is an ccc is processed as
in the case of commutative operations (2b).

The above description can be easily summarized in Prolog. For presentation
purposes, we assume that the arithmetic expression has been parsed into postfixed
Polish notation. We also assume that variables are represented by terms of the
form u (Name) and operators by terms op(Op). In an actual implementation the
semantic actions described below would be triggered directly from the DCG rules. 

The procedure gen-code(Polish, Stack, Temps) traverses the list Polish and
outputs the code as soon as it is generated. We remind the reader that a program
that produces output using writes can easily be modified so that it stores the
output in a list and thereby avoids relying on side effects to generate results (see
Section 4). The gen-code procedure is initiated with a call to the procedure
execute, defined by
\[execute(l) :- gen-code\& [ 1, [O]).\]
where L is the input in postfix. The operators and operands in the list L trigger
calls to the corresponding operator and operand clauses, which modify the Stack
as described above, and may either remove or return a location from the list 
Temps of available temporary locations:
\begin{verbatim}
gen-code([op(Op) 1 Rest], Stack, Temps) :-
operator(Op, Stack, NewStack, Temps, NewTemps),
gen-code(Rest, NewStack, NewTemps).
gen-code([u(X) 1 Rest], Stack, Temps) :-
operand(X, Stack, NewStack, Temps, NewTemps),
gen-code(Rest, NewStack, NewTemps).
gen-code([ 1, AnyStack, AnyTemps). 
\end{verbatim}

The operator and operand clauses have five parameters:

(1) the variable (or operator) being examined,

(2,3) the starting and resulting stack configurations,

(4,5) the starting and resulting lists of available temporary locations. 

The following remarks will help in understanding the semantic actions of the
procedures. The program assumes the availability of an unlimited number of
temporary locations which are reused whenever possible: a temporary is returned
to its stack after emitting an instruction of the type LOAD Ti or Op Tie The list
of available temporary locations is initialized to contain only the location T,,.
Whenever a new temporary is needed, it is taken from this list, and if the list
contains only one element a new temporary is generated (see the second clause
of get-temp below). The term t(X) is used to represent a temporary location.
\begin{verbatim}
% Case (la). ’
operand(X, [A, act 1 Stack], [u(X), A, t(I) 1 Stack], Temps, NewTemps) :-
get-temp(t(I), Temps, NewTemps),
write(st0, t(I)).
% Case (lb).
operand(X, Stack, [u(X) 1 Stack], Temps, Temps). 
\end{verbatim}
The first clause of operand guarantees that the accumulator is always the first
or second element of the stack, if it occurs at all. The other elements in the Stack
are either temporaries or variables:   
\begin{verbatim}
% Case (2b).
operator(Op, [A, act I Stack], [act 1 Stack], Temps, NewTemps) :-
codeop(Op, Instruction, AnyOpType),
gen-instr(Instruction, A, Temps, NewTemps).
% Case (2~).
operator(Op, [act, A I Stack], [act I Stack], Temps, NewTemps) :-
codeop(Op, Instruction, commute),
gen-instr(Instruction, A, Temps, NewTemps).
% Case (2d).
operator(Op, [act, A I Stack], [act I Stack], Temps, NewTemps) :-
codeop (Op, Instruction, rumcommute),
get-temp(t(Z), Temps, TempsO),
write(st0, t(Z)),
gen-instr(load, A, TempsO, Tempsl),
gen-instr(Instruction, t(I), Tempsl, NewTemps).
% Case (2a).
operator(Op, [A, B I Stack], [act I Stack], Temps, NewTemps) :- ’
A#acc,B#acc,
codeop(Op, Instruction, OpType),
gen-instr(load, B, Temps, Tempsl),
gen-instr(Instruction, A, Tempsl, NewTemps).
\end{verbatim}

Notice that at most one of the clauses for operator can succeed, since there can
be at most one act in the stack. Thus the ordering of the clauses is unimportant,
and there is no need for cuts. 

The remainder of the program consists of a few auxiliary procedures. The
procedure get-temp simulates the pop operation for a stack containing the
currently available temporary locations. Temporary locations are returned to the
stack by the first clause of gen-instr.
\begin{verbatim}
codeop(+, add, commute).
codeop (-, sub, noncommute).
codeop(*, mult, commute).
codeop(/, diu, noncommute).
gen-temp(tU), V, J I RI, [J I fW.
getj%y?y), 14, [Jl) :-
genhstr(Znstruction, t(Z), Temps, [I 1 Temps]) :-
write(Znstruction, t(Z)).
gen-instr(Znstruction, v(A), Temps, Temps) :- write(Znstruction, A). 
\end{verbatim}

The code generated for the expression A * (A * B + C - C* D) is
\begin{verbatim}
LOAD A
MULT B
ADD C
ST0 To
LOAD C
MULT D
ST0 Tl
LOAD T,,
SUB Tl
MULT A 
\end{verbatim}

An alternative approach to the method presented here is to generate new
Prolog variables to represent the temporaries as they are needed and to ensure,
in a subsequent pass, that their usage is optimized. 

\secrel{Generating Code from Trees }

A more general approach to code generation is based on “walks” in the syntaxtree
of a program. We start by describing Warren’s approach [31] for generating
code for a fictitious machine. This computer performs arithmetic operations
using a single accumulator. The corresponding instructions are ADD, MULT,
SUB, and DIV. Operations of the type ADDI, MULTI, and so on, are also
available, and consider the value immediately following them as the second
operand in the computation. LOAD and ST0 commands are of course present,
as well as the unconditional transfer (JUMP) or conditional ones such as J xx,
where xx is EQ, NE, GT, and so on. The input/output commands are simply
READ and WRITE. The generator consists of the clause encode-statement which
identifies the node of the syntax-tree and constructs the corresponding code. The
generated code is a list of instructions and labels, (possibly containing embedded
sublists), for instance,
\begin{verbatim}
[. . . label(LI), [instr(LOAD, X), instr(ADDI, 3)], . . -1 
\end{verbatim}

In Warren’s paper the arguments of instructions are stored in a dictionary,
but remain unbound to actual memory addresses until the very final phase of the
compiler. At that time an assembler determines the addresses of labels, and an
allocator binds the addresses of the variables and reserves the number of memory
locations needed to run the compiled program. We now present some fragments
of Prolog programs that perform the generation. An assignment of an expression
Expr to a variable X is translated into the list whose head is the generated code
for the expression followed by the instruction ST0 X. The procedure encodestatement
has three arguments: the syntax-tree, the dictionary Diet, and the
resulting code. We have
\begin{verbatim}
encode-statement(assign(name(X), Expr),
Diet,
[Exprcode, instr(sto, Addr)]) :-
lookup(X, Addr, Diet),
encode-expr(Expr, Diet, Exprcode). 
\end{verbatim}

The procedure lookup stores the new variable X if it is not yet entered in Diet
and retrieves the unbound variable representing its address (see Section 4). 

The procedure encode-expr can handle two shapes of arithmetic expression
syntax-trees. In the first the right operand is a leaf (i.e., a variable or a constant).
In the second the right operand is a subtree. The syntax-tree for arithmetic
expressions has internal nodes labeled by the operator Op. The more complex
case where the right operand is a subtree is presented below. Its action is to
translate expr(Op, Exprl, Expr2) (in which Expr2 is of the form expr(Op, Anyl,
Any2) into the sequence containing

(1) the code for Expr2,

(2) the instruction ST0 temp,

(3) the code for Exprl, and finally,

(4) the code for the instruction specified by Op. 

An added argument N is needed to specify the pool of temporary locations. Its
initial value is zero. In Prolog we have
\begin{verbatim}
encode-subexpr(expr(Op, Exprl, Expr2), N, Diet,
[Exprkode, instr(sto, Addr), Exprlcode, instr(Opcode, Addr)]) :-
complex (Expr2),
lookup(N, Addr, Diet),
encode-subexpr(Expr2, N, Diet, ExprZcode),
NlisN+l,
encode-szbexpr(Exprl, Nl, Diet, Exprlcode),
memoryop (Op, Opcode).
complex(expr(Op, Anyl, AnyP)).
memoryop(+, add).
memoryop(*, m&t).
\end{verbatim}

The code generated for the previous expression A* (A* B + C - C* D) now
becomes
\begin{verbatim}
LOAD C
MULT D
ST0 TO
LOAD
MULT ii
ADD C
SUB To
ST0 T,,
LOAD A
MULT T,, 
\end{verbatim}
Note that since a right subtree is evaluated before a left one, the code for C* D
is the first to be generated. 

The use of labels is illustrated by the generation of code for while statements.
The translation consists of transforming the syntax-tree while (Test, Do) into the
code
\begin{verbatim}
hbel(L1): (encode Test)
(encode Do )
jump Ll
lubel(L2): 
\end{verbatim}

Note that a new argument (L2) is needed in the procedure that encodes tests
to generate the jump to the exit label. The Prolog program to achieve the
translation parallels the above description.
\begin{verbatim}
encode-statement (while (Test, Do), Diet,
[hbel(Ll), Testcode, Docode, in&( jump, Ll), bbel(L2)]) :-
encode-test (Test, Diet, L2, Testcode),
encode-statement(Do, Diet, Docode). 
\end{verbatim}

\secrel{A Machine-Independent Algorithm for Code Generation }

An alternate approach to code generation is that proposed by Glanville and
Graham [15, 16]. It is assumed that by syntax-directed translation a source
program is translated into its prefix Polish counterpart. A second syntax-directed
translation of the prefix code then produces actual machine code. The interesting
feature of this approach is that the grammar used to recognize the prefix takes
into consideration the description of the machine for which code is generated.
Consider a register machine whose operations are of the type
\[LOAD M, R\]
\[ADD R1, R2 or ADD M, R\]
\[ST0 R, M\]
\[ADDI C, R\]
where M is a memory address, C is a constant, and R is a register, and the first
argument is the source, the second the destination. To simplify the presentation,
we assume an unlimited pool of registers. The problem of dealing with a limited
number of registers is discussed in the next section.

The grammar rule
\[R + op R var 1 var\]
describes a prefix string in which the last operand is always a variable, (e.g., as
in + + a b c). The code to be generated in this case can be triggered by semantic
actions corresponding to the rules 

\[R + var\]
Action: Load variable into register r

\[R + op R var\]
Action: 1. recognize (recursively) the left operand R assuming that it will
use register r

2. generate the code: op var r

Similar grammar rules are applicable for generating code when the last operand
is a constant. The more general case corresponds to the grammar rule
\[R + op R R 1 var 1 const\]

In this case a new register is needed before recursing to the second R. Also, a
register becomes available after recognizing the second R. A natural way of
implementing the Glanville-Graham approach is through the use of DCGs. The
following simplified grammar rules express assignments:
\[A + := var R\]
\[R+opRvar~opRconst\]
\[R-+opRR\]
\[R + var I const\]

Note that this is an ambiguous grammar, and therefore the use of cuts at the end
of each clause is recommended to avoid generating multiple solutions. The
recursive descent compiler generated from the DCGs opts, whenever possible, to
the first rule defining R, instead of the more general second rule. 

The procedures listed below specify the syntax-directed translation of prefix
Polish into assembly language according to the above grammar rules. The
procedure reg corresponds to the nonterminal R and has three parameters:

(1) generated assembly language sequence,

(2) register containing the final result,

(3) dictionary for storing variables.   

Although the presented program assumes an unlimited number of registers, it is
fairly straightforward to modify it to consider a finite number only. This can be
done by adding extra parameters to the procedure reg. 

The first two clauses of reg treat the special cases where the second parameter
is a variable or a constant:
\begin{verbatim}
% Rule:R+OpRvar.
reg([Sl, imtr(Op, Addr, Rl)], Rl, D) --+
arithop(Op, Optwe),
regC% RL D),
[uar(Var)l,
(lookup( Var, D, Addr), !).
\end{verbatim}
\begin{verbatim}
% Rule: R --, Op R const.
reg([Sl, instr(Constop, C, Rl)], Rl, D) --+
arithop(Op, Optwe),
redsl, RI, D),
bdC)l,
{constop(op, Con-stop), !). 
\end{verbatim}

where arithop and constop are defined as
\begin{align*}
arithop(sub, noncommute) &\rightarrow\ [-I. &arithopbdd, commute) --+ [+I.\\
arithop(diu, noncommute) &\rightarrow\ [/I. &arithp(nult, commute) --+ [*I.\\
constop(sub, subi). &&constop(diu, diui).\\
constop(add, addi). &&constop(mult, multi). \\
\end{align*}

It is possible to perform some optimization in the case of commutative operations.
For that purpose two additional DCG clauses are included to process the rules:
\[R + op var R and R + op const R\]

The DCG clause for the first of these rules is given below.
\begin{verbatim}
% Rule: R -+ op uar R(op is commutatiue).
reg([Sl, instr(Op, Addr, Rl)], Rl, D) --+
arithop(Op, commute),
[udVar)l,
reg(S1, RI, D),
(lookup( Var, Addr, D), !I.  
\end{verbatim}

The more complex DCG given below corresponds to the rule R + op R R.
\begin{verbatim}
% Rule:R-*opRR.
reg([Sl, S2, instr(Op, R2, Rl)], Rl, D) --+
arithop(Op),
redS1, RI, D),
(R2 is Rl + 1),
reg(S2, R2, D), (!). 
\end{verbatim}

Two recursive calls are made to reg to determine the subsequences Sl and S2
representing the code for calculating the two operands. The simple DCG clauses
for the rules R + uar and R + const generate the necessary instructions that
load a register with a variable or with a constant.
\begin{verbatim}
% Rule: R + var.
reg(instr(load, Addr, Rl), Rl, D) --+
[MVar)l,
{lookup( Var, D, Addr), !).
% Rule: R + const.
reg(instr(hzdc, C, Rl), Rl, D) --+
[co=dC)l, 1% 
\end{verbatim}

Finally, we present the DCG clause for generating an assignment expressed in
prefix by the rule
\[A + := var R.\]
\begin{verbatim}
% Code generator for assignments.
instruction([Sl, instr(store, 1, Addr)], D) --+
[assign, uar (Vur)],
red% 0, D),
(lookup( Var, Addr, D)]. 
\end{verbatim}

Notice that the chosen grammar relies extensively on backtracking for recognizing
the appropriate rule. For example, consider the two rules
\[R --+ Op R const\]
\[R --+ Op R var\]
and the input string (+ + 5 c d). Although the first rule will not apply, it will
nonetheless be tried, and the code for the expression (+ 5 c) will be generated
before backtracking. The same code will then have to be regenerated when the
second rule is applied. This can be avoided by considering the following transformed
equivalent grammar:
\[R --+ Op R R2\]
\[R2 --+ Var 1 Const\]

This transformation can be easily generalized to the case at hand, and the
resulting parser will not rely on backtracking so there will be no need to insert
cuts into the program. 

An example of the code generated by this technique for the expression
,*(A* B + C - C*(D - E)) is
\begin{verbatim}
LOAD B, RO
MULT A, RO
ADD C, RO
LOAD D, Rl
SUB E, Rl
MULT C, RI
SUB Rl, RO
MULT A. RO  
\end{verbatim}
   
\secup