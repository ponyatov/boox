\secrel{ASTLOG: Язык для анализа синтаксических деревьев}\secdown
\cp{\url{http://www.cs.nyu.edu/~lharris/papers/crew.pdf}}
\copyright\ Roger F. Crew \email{rfc@microsoft.com}\\
Microsoft Research
Microsoft Corporation
Redmond, WA 98052

\secly{Abstract}

We desired a facility for locating/analyzing syntactic artifacts in abstract
syntax trees of \ci/\cpp\ programs, similar to the facility \prog{grep} or
\prog{awk} provides for locating artifacts at the lexical level. \prolog, with
its implicit pattern-matching and backtracking capabilities, is a natural choice
for such an application. We have developed a \prolog\ variant that avoids the
overhead of translating the source syntactic structures into the form of a
\prolog\ database; this is crucial to obtaining acceptable performance on large
programs. An interpreter for this language has been implemented and used find
various kinds of syntactic bugs and other questionable constructs in real
programs like \prog{Microsoft SQL server} (450Klines) and \prog{Microsoft Word}
(2Mlines) in time comparable to the runtime of the actual compiler.

The model in which terms are matched against an implicit current object, rather
than simply proven against a database of facts, leads to a distinct ``inside-out
functional'' programming style that is quite unlike typical \prolog, but one
that is, in fact, well-suited to the examination of trees. Also, various second-order
\prolog\ set-predicates may be implemented via manipulation of the current
object, thus retaining an important feature without entailing that the database
be dynamically extensible as the usual implementation does.

\secrel{Introduction}\secdown

Tools like \prog{grep} and \prog{awk} are useful for finding and analyzing
lexical artifacts; e.g., a one-line command locates all occurences of a
particular string. Unfortunately, many simple facts about programs are less
accessible at the character/token level, such as the locations of assignments to
a particular \cpp\ class member. In general, reliably extracting such syntactic
constructs requires writing a parser or some fragment thereof. And after writing
one's twenty-seventh parser fragment, one might begin to yearn for a more
general tool capable of operating at the syntax-tree level.

Even given a compiler front-end that exposes the abstract syntax tree (AST)
representation for a given program, there remains the question of what exactly
to do with it. To be sure, supplying a \ci\ programmer with a sufficiently
complete interface to this representation generally solves any problem one might
care to pose about it. One may just as easily say that all problems at the
lexical level may be solved via proper use of the UNIX standard IO library
\verb|<stdio.h>|, a true, but utterly trivial and unsatisfying statement. The
question is rather that of building a simpler, more useful and flexible
interface: one that is less error-prone, more concise than writing in \ci, and
more directly suited to the task of exploring ASTs. We first consider a couple
of prior approaches.

\secrel{The \prog{awk} Approach}

One of the more popular approaches is to extend the \prog{awk} \cite{AKW86}
paradigm. An \prog{awk} script is a list of pairs, each being a
regular-expression with an accompanying statement in a C-like imperative
language. For each line in the input file, we consider each pair of the script
in turn; if the regular-expression matches the line, the corresponding statement
is executed.

Extending this to the AST domain is straightforward, though with numerous
variations. One defines a regular-expression-like language in which to express
tree patterns and an \prog{awk}-like imperative language for statements. The
tree nodes of the input program are traversed in some order (e.g., preorder),
and for each node the various pairs of the script are considered as before.

We have two objections to this approach, the first having to do with the
hardwired framework that usually implicit. In some cases (e. g., \prog{TAWK}
\cite{GA96}), the traversal order for the AST nodes is essentially fixed; using
a different order would be analogous to attempting to use plain \prog{awk} to
scan the lines of a text file in reverse order. In $A*$ \cite{LR95}, while the
user may define a general traversal order, only one traversal method may be
defined/active at any given time, making difficult any structure comparisons
between subtrees or other applications that require multiple concurrent
traversals. Since the imperative language is quite general in both cases, little
is deffinitively impossible, however for some applications one may be little
better off than when programming in straight \ci.

The second objection has to do with the kinds of pattern-abstraction available.
Inevitably there exist simply-described patterns that are a poor fit to a
regular-expression-like syntax. This tends to happen when said simple
descriptions are in terms of the idioms of a particular programming language;
most of the various tree-\prog{awk} pattern languages tend to be designed with
the intent of being language independent.

Suppose one wishes to find all consecutive occurrences of one statement
immediately preceding another, e. g., places where a given system call
\verb|syscall();| is followed immediately by an \verb|assert();| \note{on the
theory that testing of outcomes of system calls should be done in production
code rather than just debugging code}. A tree-regular-expression pattern of the
form

\begin{verbatim}
<syscall() pattern>; <assert() pattern>
\end{verbatim}

\noindent
(where \verb|;| is the regular-expression sequence operator) finds all instances
of the two calls occurring consecutively within a single block, but it misses
instances like

\begin{verbatim}
syscall();
{
    assert();
    ...
}
\end{verbatim}

and

\begin{verbatim}
if (...) {
    syscall();
}
else {
    ...
}
assert();
\end{verbatim}

While the tree-\prog{awk} languages allow one to write patterns to match each of
these cases, without a pattern-abstraction facility, we may be back at square
one when it comes time to look for some \emph{different} pair of consecutive
function calls. We prefer to write a single consecutive-statement pattern
constructor \emph{once} and then be able to use it for a variety of cases where
we need to find pairs of consecutive statements satisfying certain criteria,
invoking it as

\begin{verbatim}
follow_stmt(<syscall() pattern>, <assert() pattern>)
\end{verbatim}
for the above problem, or, if we instead want to be fiding all of the places
where a \ci\ switch-case falls through, as
\begin{verbatim}
follow_stmt(not(<unconditional-jump pattern>),
                <case-labeled stmt pattern>)
\end{verbatim}

One solution, used by \prog{TAWK}, is to use \prog{cpp}, the C preprocessor, to
preprocess the script, allowing for pattern-abstractions to be expressed as
\verb|#define| macros whose invocations are then expanded as needed. This is
unsatisfactory in a number of ways, whether one wants to consider the problem of
recursively-defined patterns, macros with large bodies that result in a
corresponding blow-up in the size of the script, or the difficulty of tracing
script errors that resulted from complex macro-expansions.

Another way out is to fall back on the procedural abstraction available in the
imperative language that the patterns invoke. One essentially uses a degenerate
pattern that always matches and then allows the imperative code to test whether
the given node is in fact the desired match, defining functions to test for
particular patterns. Once again, it seems we are back to programming in straight
C and not deriving as much benefit from having a pattern language available as
we could be.

In general, the philosophical underpinning of the \prog{awk} approach is that
the designer has already determined the kinds of searches the user will want to
do; the effort is put towards making those particular searches run efficiently.
There is also an assumption that the underlying imperative language for the
actions has all the abstraction facilities one will ever need, so that if the
pattern language is lacking in various ways, this is not deemed a serious
problem. While this is not an unreasonable approach, we have less confidence of
having identified all of the reasonable search possibilities, and thus would
prefer instead to make the pattern language more flexible and extensible, being
willing to sacrifice some efficiency to do so.

\secrel{The Logic Programming Approach}

Another common approach is to run an inference engine over a database of program
syntactic structures \cite{BCD88, BGV90, CMR92}. \prolog\ \cite{SS86} is a
convenient language for this sort of application. Backtracking and a form of
pattern matching are built in, the abstraction mechanisms to build up complex
predicates exist at a fundamental level, andfinally, \prolog\ allows for a more
declarative programming style.

The problems with using \prolog\ are two-fold. First there is the issue of
efficiency. Second, we must represent the AST for our source program in the
\prolog\ database. Large programs ($10^5..10^6$ lines) will result in
correspondingly large \prolog\ databases, most likely with a significant
performance penalty.

We finesse the second problem by not attempting to import the source program's
AST at all, instead opting to modify the interpretation of the predicates and
queries of \prolog\ so as to be applicable to external objects rather than just
facts provable in the existing database. Removing reasons that require the
database to grow beyond the initial script creates significant opportunities for
optimization. This, however, requires removing primitives like \verb|assert()|
and \verb|retract()| that allow for the dynamic (re)defiition or removal of
predicates, which in turn removes many higher-order logical features that are
defined in terms of them. Fortunately, some of the more essential ones can be
restored at relatively little cost.

\secup

\secrel{Elements of ASTLOG}\secdown

Section \ref{crewsyntax} gives the complete syntax for our language, ASTLOG. The
ASTLOG interpreter reads a script of user-defined predicate operator definitions
and then runs one or more queries.

As in \prolog, the definition of a user-defined predicate operator is composed
of one or more \term{clauses}. A compound term \verb|opname(term,...)| appearing
at top level in a clause body is interpreted as a predicate, whether
\term{opname} be primitive or user-defined. In the latter case, the script is
searched for a defining clause whose head terms successfully unify with the
respective operand terms of the given compound term, variables are bound
accordingly, and the terms of the clause body are likewise interpreted. The
clause \emph{succeeds} (i. e., is found to be true) if all of its body terms
succeed. Whenever a clause head fails to unify, or a clause body term
\emph{fails} (i. e., is found to be false), or any primitive term fails by the
rules of evaluation of that primitive, we backtrack to the last point where
there was a choice (e. g., of clauses to try for a given compound term) and
continue.

A \term{query} is a clause whose head terms are all variables. Ultimately,
whenever all terms of a query body succeed, the bindings of any variables listed
in the query head (\term{qhead}) are reported. Otherwise, we report failure.
Thus far, this is all exactly like \prolog.

\subsecly{Figure 1: Complete Syntax of ASTLOG}\label{crewsyntax} 

\begin{tabular}{l l l}
script & ::= named-clause* & script file syntax \\
query & ::= imports? ( varname* ) clause-body ; & query syntax \\
imports & ::= \{ varname+ \} &\\
named-clause & ::= opname anon-clause &\\
anon-clause & ::= ( term* ) clause-body? ; &\\
clause-body & ::= <- term+ &\\
\end{tabular}

\noindent
\begin{tabular}{l l l}
\hline
&Essential Term Syntax&\\
\hline
term & ::= literal & reference to denotable ob ject \\
& ::= varname &\\
& ::= opname ( term* ) & compound term \\
& ::= FN imports? ( anon-clause+ ) & anonymous predicate-operator-valued 
\\&&(``lambda'') term \\
& ::= ' opname arity-spec? & named predicate-operator-valued
\\&&(``function quote'') term \\
& ::= ( term )( term* ) & ``application'' term \\ 
\end{tabular}

\noindent
\begin{tabular}{l l l}
\hline
&Gratuitous Term Syntax&\\
\hline
&::= \# constname & named constant\\&&($\equiv$ corresponding literal number)\\
&::= \verb|[ term* ]| & \verb|[ ]| $\equiv$ nil(), \verb|[term]| $\equiv$
cons(term; nil()), etc\ldots\\
&::= \verb$[ term+ | term ]$ & \verb$[ term1 | term2 ]$ $\equiv$
cons(term1,term2), etc\ldots\\
arity-spec & ::= / integer &\\ 
\end{tabular}

\secrel{Objects}

ASTLOG refers to external objects. Given a \ci/\cpp\ compiler front end that
provides a (\cpp) interface to the syntactic/semantic data structures built
during the parse of a given program, it is simple to graft this onto the core of
ASTLOG so that it may recognize object references corresponding to
\begin{itemize}[nosep]
  \item whole C/C++ programs,
  \item single files,
  \item symbols,
  \item AST nodes (including statements, expressions, and declarations), and
  \item \ci/\cpp\ type descriptions.
\end{itemize}

For the purposes of ASTLOG, an \term{object} is simply some external entity that
is significant for its identity and for the primitive predicates that it may
satisfy. To simplify the language we regard the traditional
constants (integers, floats, and strings) to be references to ``external''
objects as well, though one could just as easily take the converse view in which
the universe of object references is just a (very large) pool of
constants\note{``atoms'' in the usual \prolog\ terminology}.

In any case, object references are terms in ASTLOG. Only references to equal
objects can unify, equality meaning numeric equality for numbers,
same-sequence-of-characters for strings, and identity for all other classes of
objects. Only objects that have denotations (numbers, strings and the unique
\verb|null object*|) can find their way into scripts.

\secrel{The Current Object}

The first significant departure from the \prolog\ model is that a query or
predicate term always evaluates under an ambient \term{current object}. Every
query and every term being evaluated as a predicate is not so much a standalone
statement that may or may not be intrinsically true (i. e., provable from the
``facts'' in the script) as it is a specification that may or may not be
satisfied by the current ob ject, or, alternatively, a \term{pattern} that may
or may not \term{match} the current object. For example, in \prolog
\begin{verbatim}
odd(3)
\end{verbatim}
always succeeds by virtue of 3 being odd or because the ``fact'' \verb|odd(3)|
exists in the script somewhere. By contrast, in ASTLOG
\begin{verbatim}
odd()
\end{verbatim}
succeeds if the current object happens to be the integer 3, fails if the current
object is 4, and raises an error if the current object is the string
\verb|"Hi mom"|. Another way to view this is that every predicate term takes an
extra, hidden current-object operand.

While one normally only expects to see compound (and application) terms in
predicate position, ASTLOG allows variables and ob ject references there as
well. The rules for matching are as follows:

\begin{itemize}
  \item 
An object reference matches the current object, if it references an equal
object.
  \item 
A bound variable matches according as whatever term it is bound to.
  \item 
An unbound variable gets bound to reference the current ob ject (and thus
automatically matches it).
\item 
A compound term whose operator is defined via clauses matches if there exists a
clause whose head operands unify with the term operands and whose body terms
themselves all match the current object.
\end{itemize}

Section \ref{crew31} describes the operator-valued and application terms.

The evaluation rules for compound terms having primitive operators are widely
varied, however the operands are usually treated one of two ways:

\begin{enumerate}
  \item 
\verb|(foo-pred)| requiring the operand to be match some object\note{which
becomes the current object for that evaluation}, not necessarily the same
current object as that which the full term is being matched against. For
example, the operand of \verb|strlen| (see \ref{crewfig2}) and the second
operand of \verb|with| are treated this way.
  \item 
\verb|(foo)| requiring the operand be an object reference, whether this be a
literal or an object-reference-bound variable. The operands of \verb|re|,
\verb|gt|, and the first operand of \verb|with| are treated this way.
\end{enumerate}

Most primitives also expect a current ob ject to be of a particular kind and
raise an error if confronted with something different.

The use of an implicit current object is not by itself an increase in
expressivity. If we had, in a \prolog\ database, terms representing the various
AST nodes, there would be a fairly straightforward translation of ASTLOG terms
into \prolog\ terms, one in which we simply modify all terms to make the current
object an explicit operand.

Nevertheless, ASTLOG programs exhibit a distinct style of programming. Consider
as an example that we might, in a typical functional language, write a function
call
\begin{verbatim}
strlen(string)
\end{verbatim}
to find the length of the string returned by the expression \verb|string|. Here
the length result is implicitly returned to the context of the call. In \prolog,
the natural style would be to express this as a relation
\begin{verbatim}
strlen(string, length)
\end{verbatim}
which stipulates that \verb|length| is in fact the length of \verb|string|. In
ASTLOG, we would write
\begin{verbatim}
strlen(length-pred)
\end{verbatim}
where now it is the \verb|string| argument that is implicitly supplied \emph{as
the current object} \textit{by} the context while the length result is returned
\textit{to} the subterm \verb|length-pred|, which in turn can be some arbitrary
term expecting a numeric current ob ject as its implicit argument. For example,
given an \verb|odd()| predicate as above, the term \verb|strlen(odd())| would
match any string consisting of an odd number of characters. It is this
``inside-out functional'' evaluation strategy that makes ASTLOG well-suited to
constructing anchored patterns to match tree-like structures.

\subsecly{Figure 2: Some core ASTLOG primitives}\label{crewfig2}

\begin{itemize}
  \item 
\verb|and(object-pred,... )|\\
The current object satisfies every \verb|object-pred| operand. 
  \item 
\verb|or(object-pred,... )|\\
The current object satisfies some \verb|object-pred| operand. 
  \item 
\verb|if(object-pred, then-pred, else-pred)|\\
The current object satisfies \verb|then-pred| or \verb|else-pred| according as
it satisfies or fails to satisfy \verb|object-pred| (once; if \verb|object-pred|
matches but \verb|then-pred| does not, we do not retry \verb|object-pred|). 
  \item 
\verb|not(object-pred)|\\
\verb|= if(object-pred, or(), and())|
  \item 
\verb|with(object, object-pred)|\\
\verb|object| satisfies \verb|object-pred| (outer current object is ignored).
  \item 
\verb|strlen(integer-pred)|\\
The current string object has length satisfying \verb|integer-pred|. 
  \item 
\verb|re(string)|\\
The regular expression \verb|string| matches the current string. 
  \item 
\verb|gt(integer)|\\
The current integer is greater than \verb|integer|. 
  \item 
\verb|minus(integer-pred, integer)|\\
\verb|integer-pred| matches the current integer \verb|+ integer|. 
  \item 
\verb|minus(integer, integer-pred)|\\
\verb|integer-pred| matches \verb|integer|\ --- the current integer.\\
(An error is raised if neither operand of a minus term
is an integer ob ject reference.) 
  \item 
\verb|plus(integer-pred, integer)|\\
\verb|integer-pred| matches the current integer\ --- \verb|integer|

\subsecly{Figure 3: Some primitive node and symbol predicates}
  \item 
\verb|parent(ast-pred)|\\
This AST node is not a root node and its parent satisfies \verb|ast-pred|.
  \item 
\verb|kid(integer-pred; ast-pred)|\\
This AST node has a child satisfying \verb|ast-pred| whose (0-based) index
satisfies \verb|integer-pred|.
  \item 
\verb|kidcount(integer-pred)|\\
The number of children of this AST node satifies \verb|integer-pred|. 
  \item 
\verb|op(integer-pred)|\\
The opcode of this AST node satisfies \verb|integer-pred|. 
  \item 
\verb|atype(type-pred)|\\
This AST node has a return type satisfying \verb|type-pred|. 
  \item 
\verb|asym(symbol-pred)|\\
This AST node is a symbol satisfying \verb|symbol-pred|. 
  \item 
\verb|aconst(const-pred)|\\
This AST node is a constant (integer, float or string) satisfying
\verb|const-pred|.
  \item 
\verb|sname(string-pred)|\\
This symbol's name satisfies \verb|string-pred|. 
\end{itemize}

There are named constants available for designating the opcodes of various kinds
of nodes for use in \verb|op()| terms, and the indices of particular children
for use in \verb|kid()|.

\secrel{Examples}

Given the set of AST node primitives in Figure 3, we could write
\begin{verbatim}
and(op(#=), kid(#LEFT, asym(sname("foo"))))
\end{verbatim}
which would be satisified by any AST node that is an assignment (=) expression
whose left-hand side is itself a symbol expression where the symbol name is
"foo". Here, \verb|#=| and \verb|#LEFT| are numeric literals for the assignment
node opcode and the assignment target's childindex, respectively.

To define a predicate \verb|assignment/2| to match assignment nodes, a script
could include the clause
\begin{verbatim}
assignment(target, value)
    <- op(#=),
        kid(#LEFT, target),
        kid(#RIGHT, value);
\end{verbatim}
which would then allow writing the previous term as
\begin{verbatim}
assignment(asym(sname("foo")), _)
\end{verbatim}

As in \prolog, the underscore \verb|(_)| is ``wild-card'' variable, i.e., one
that is internally given a distinct identity so as not to be conated with any
other instances of \verb|_|. Such a variable, being guaranteed to be unbound,
will match any o ject or unify with any term.

Defining a general purpose node-traversal predicate is also straightforward
\begin{verbatim}
somenode(pred)
    <- or(pred, kid(_ , somenode(pred)));
\end{verbatim}
Given this definition, an attempt to match \verb|somenode(test)| to a given node
will create an instance of the defining clause of \verb|somenode/1| above with
pred bound to \verb|test|. Satisfying the clause body requires that either
\verb|pred| match the current node, or, if (when) that fails, that
\verb|kid(_,somenode(pred))| match the current node. The latter in turn will
attempt to match the variable \verb|_| with 0 (easy) and the term
\verb|somenode(pred)| with the first child, and, when that fails, \verb|_| with
1 and \verb|somenode(pred)| with the second child, etc\ldots Making the
interpreter fail and backtrack after each hit (in the usual manner of \prolog)
eventually causes \verb|test| to be matched with the original node and all of
its descendants.

So, if we issue the query
\begin{verbatim}
(v) <- somenode(
    assignment(asym(sname("foo")), v)
        );
\end{verbatim}
on the root node of some function's AST, we obtain, via the successive bindings
reported for \verb|v| on each hit, all of the expressions assigned to variables
named \var{"foo"} within that function.

As an example that makes less trivial use of backtracking, consider the problem
of whether two trees have the same structure (i.e., root nodes have the same
opcode and all corresponding children have the same structure).
\begin{verbatim}
sametree(node)
    <- op(nodeop),
       with(node, op(nodeop)),
       not(and(with(node, kid(n, nkid)),
           kid(n, not(sametree(nkid)))));
\end{verbatim}

This defines a predicate \verb|sametree(node)| that holds if \verb|node| is a
reference to an AST node with the same structure as the current object. The
first line of the clause body binds the current node's opcode to \verb|nodeop|,
the second line compares that to the opcode of \verb|node|, while the remaining
lines search for children whose subtrees have distinct structure. The term
\verb|kid(n, nkid)| will match each child of \verb|node|, since both variables
are initially unbound. If \verb|sametree(nkid)| happens to be true of the
corresponding child of the current node, the inner \verb|not| fails and we go
back and try another child of \verb|node|. If \verb|sametree(nkid)| happens to
be true of \emph{every} corresponding child of the current node, then the
enclosing \verb|not| and thus the outer \verb|sametree(node)| invocation
succeeds.

The preceding version of \verb|sametree/1| is a purely
structural comparison; there is no attempt to take account
of the commutativity/associativity of the various
operators, e. g., \verb|a + b| and \verb|b + a| are not considered
the same. If, say, we \emph{did} want to consider commutativity,
we could define
\begin{verbatim}
csametree(node)
    <- op(nodeop),
       with(node,op(nodeop)),
       kidcount(if(with(nodeop,commutes()),
                    any_perm(perm),
                    id_perm(perm))),
       not(and(with(node,kid(corresp(perm,n),
                            nkid)),
                kid(n,not(csametree(nkid)))));
\end{verbatim}
along with suitable definitions of
\begin{description}
\item[commutes()]\ \\
the current integer is the opcode of a commutative operator,
\item[any\_perm(perm)]\ \\
\verb|perm| is any permutation of the sequence\\
\verb|0, ... , (<current-object> - 1)|,
\item[id\_perm(perm)]\ \\
\verb|perm| is the identity permutation of the sequence\\
\verb|0, ... , (<current-object> - 1)|,
\item[corresp(perm, n)]\ \\
permutation \verb|perm| takes the current integer to something matching
\verb|n|.
\end{description}
Here, permutations can be represented by list terms. Note that since all of the
commutative \ci/\cpp operators are, in fact, binary, this all simplifies
significantly.

It should, incidentally, be clear that there is nothing about the core language
that is specifically tailored for the examination of compiler-produced ASTs, let
alone ASTs for a given language. The language in fact lends itself to the
examination of a wide variety of external structures, e. g., hierarchical file
systems, or collections of web pages. All that is needed is a suitable
collection of primitive ASTLOG predicates for querying said structures.

\subsecly{Figure 4: Actual ASTLOG code for follow\_stmt}

Actual ASTLOG code for \verb|follow_stmt| and how one uses it to find case
statement fallthroughs. The cond operator is an if-then-elseif- construct, that
is, \verb|cond(p1, e1, p2, e2,..., e)| is equivalent to
\verb|if(p1, e1,if(p2,e2,..,e))|. \verb|sfa(emit(string))| always succeeds and,
as a side-effect, emits the source location of the current AST node in
grep-output form.

\lstx{\file{follow\_stmt.astlog}}{prolog/crew/follow.pl}

\subsecly{Figure 5: Definition of \file{flatten}}\label{crewfig5}

\begin{verbatim}
flatten(test, lst)
  <- flatten(test, lst, []);

flatten(test, head, tail)
  <- if(test,
        first(head, hrest),
        unify(head, hrest)),
     flattenkids(test, 0, hrest, tail);

flattenkids(test, n, head, tail)
  <- if(kid(n, flatten(test, head, mid)),
        and(with(n, minus(nplus1,1)),
            flattenkids(test, nplus1,
                        mid, tail)),
        unify(head, tail));

first([o|rest],rest) <- o;
unify(x,x);
\end{verbatim}

\subsecly{Figure 6: Parameterized version, \file{flatten2}}\label{crewfig6}

\begin{verbatim}
flatten2(test, lst)
  <- flatten2(test, lst, []);

flatten2(test, head, tail)
  <- if((test)(value),
        unify(head, [value|hrest]),
        unify(head, hrest)),
     flatten2kids(test, 0, hrest, tail);

flatten2kids(test, n, head, tail)
  <- if(kid(n, flatten2(test, head, mid)),
        and(with(n, minus(nplus1,1)),
            flatten2kids(test, nplus1,
                         mid, tail)),
        unify(head, tail));

unify(x,x);
\end{verbatim}

\secup %2

\secrel{Higher order features}\secdown %3

We have already included some of the non-1st-order features of \prolog, notably
``cut'' (in the form of \verb|if()|) and the corresponding notion of negation,
\verb|not()|. There are others that turn out to be essential as well.

\secrel{3.1 Lambdas and Applications}\label{crew31}

One may observe that, in \verb|somenode(test)|, because this is an existential
query, it does not matter that we are matching the same term \verb|test| to
every node of the tree. If variables in \verb|test| get bound as a result of
matching a given node, those bindings will be undone prior to advancing to the
next node.

If one instead wants to write a conjunctive predicate over all tree nodes, say
\begin{verbatim}
flatten(test, list)
\end{verbatim}
which holds if \verb|list| is a list of \emph{all} descendant nodes satisfying
\verb|test|,\ --- we give a definition in Figure 5\ --- this will not work
correctly if \verb|test| contains any variables that are bound during the course
of matching any node; said variables will \emph{stay} bound for the duration of
the \verb|flatten| evaluation.

Even in an existential query, there is the possibility that the \verb|test|
being passed in will itself need to take a parameter. For example, one might
imagine defining a version of \verb|sametree| that also requires an additional
user-specified \verb|test| to hold at each corresponding pair of nodes. If
\verb|test| is a mere compound term, it can be matched against one of the nodes,
but not both.

Thus we introduce \termdef{``application'' terms}{application term} and
operator-valued \termdef{``lambda'' terms}{lamdba term}. For an application
\verb|(fterm)(term;...)| to match the current object, the term \verb|fterm| must
be (or be a variable bound to) a predicate-operator-valued term, which will
either be
\begin{itemize}
  \item a reference, \verb|'foo/3| to a named predicate operator,
in which case the application evaluates exactly as the corresponding compound
term would, or
\item an anonymous predicate operator
\verb|FN{importvars ... }(anon-clauses ...)|, in which case the application
evaluates \emph{almost} exactly as if there were a named predicate-operator
defined by the given clauses and this were a compound term on that operator. The
difference is that any variables of those clauses that are also on the
\verb|{importvars... }| list are identified with the correspondingly-named
variables in the clause where the \verb|FN| term occurs lexically.
\end{itemize}

An \verb|FN| term with imports can be thought of as a kind of
\termdef{closure}{closure}.

The parameterized version of flatten, namely
\begin{verbatim}
flatten2(test, list)
\end{verbatim}
which holds iff list is a list of all x corresponding to
descendants that \verb|(test)(x)| matches, is defined in Figure
\ref{crefig6}.

\subsecly{Figure 7: Parameterized version of sametree}\label{crewfig7}
\begin{verbatim}
sametree(node,equiv)
<- unify(same,
FN{same,equiv}
((node)
<- op(nodeop),
with(node,op(nodeop)),
(equiv)(node),
not(and(with(node,kid(n,nkid)),
kid(n,not((same)(nkid))))))),
(same)(node);
\end{verbatim}

The parameterized version of sametree is invoked as
\begin{verbatim}
sametree(node, equiv)
\end{verbatim}
which holds iff node is a reference to an AST node with
the same tree structure as the current node and, for
every descendant n of node, the corresponding node in
the current tree satisfies \verb|equiv(n);| this predicate is defined in Figure
\ref{crewfig7}. This definition demonstrates the use
of import lists, both to define a recursive anonymous
predicate, and to make equiv available at once to all
evaluations of that predicate. Given that definition,
the following
\begin{verbatim}
sametree(node,
FN((n) <- if(aconst(c),
 with(n, aconst(c)),
  and());))
\end{verbatim}
would then test whether the current tree has the same
structure as underneath node and such that all corresponding
constants are the same.

\subsecly{Figure 8: Embedded Query State Primitives}\label{crewfig8}

\begin{description}
\item[query(fterm; query-pred)]\ \\
The embedded query state object created from fterm satisfies query-pred.
\item[qnext(pred; thisquery-pred; nextquery-pred)]\ \\
If the current embedded query state is a failure, pred is true, otherwise the
current object satisfies this query-pred and, after the embedded query is
advanced to the next hit or to failure, the resulting query state satisfies
nextquery-pred.
\item[qget(object-pred;::: )]\ \\
Each object-pred matches the ob ject bound to the corresponding variable in the
head of the embedded query corresponding to the current query state object.
An error will be raised if the embedded query has failed or if any head variable
is not bound to an object.
\end{description}

\secrel{Queries as Objects}

Sometimes one wishes to build a collection or some other kind of aggregate of
all ob jects found by a query. Unfortunately, when backtracking to get to the
next hit, information about the previous hit will generally be lost. One
solution is to rewrite the query into a conjunctive form, as we did in the
previous section converting writing flatten as a conjunctive version of somenode
(see Figure \ref{crewfig5}). We can already see that even in simple cases this
process can be non-trivial and is not readily generalized.

It may also be the case for some conjunctive queries
that they require memory proportional to the size of
the data structure being searched, instead of merely
memory proportional to the depth of the data structure.
Judicious use of if() | astlog's moral equivalent
of the cut operator | can avoid this, but this is
sometimes cumbersome to get right.

As it happens, Prolog provides a number of setpredicates for accumulating query
results. For example,
\begin{verbatim}
bagof(x, term, list)
\end{verbatim}
binds list to a list of the bindings of x corresponding to each instance where
term holds true. Unfortunately, this is usually implemented in terms of assert
and retract, meaning we would have to abandon the idea
of keeping our script small and fixed. Even just adding
this as a new primitive is dubious if we have to add,
say, another new primitive to merely count query hits,
and yet more new primitives for each accumulation
method anyone dreams up.

The key observation is that the execution model of
astlog allows for the possibility of treating some subset
of its own internal structures as ``external'' objects
which can then serve as the current ob ject of various
kinds of queries. To be sure, some care needs to be exercised,
since the internal structures of astlog are not
static the way the program asts are. We can however,
take a query whose hits we wish to accumulate, and
encapsulate its state after a given hit as an astlog
ob ject. Such an embedded query in a given state can
now be the current ob ject for the evaluation of some
other predicate term. We thus only need to provide
suitable primitive predicates applicable to query-state
ob jects that may be used in such a term. Figure \ref{crewfig8} lists
these primitives.

\subsecly{Figure 9: Query Accumulators qcount and qlist}\label{crewfig9}

\begin{verbatim}
qcount(n) <- qcount(0, n);
qcount(sofar, return)
<- qnext(unify(sofar, return),
with(sofar, minus(sofarp1,1)),
qcount(sofarp1, return));
qlist(lst)
<- qnext(unify(lst, []),
qget(first(lst,rest)),
qlist(rest));
// utilities
first([o|rest],rest) <- o;
unify(x,x);
\end{verbatim}

Using this mechanism, it is then possible to define
a wide variety of accumulators of query results. Given
an ast node, and a query to see if there exists a descendant
satisfying \verb|test(x)|
\begin{verbatim}
() <- somenode(test(x));
\end{verbatim}
the corresponding query to count the number of descendants
satisfying test(x) would be
\begin{verbatim}
(n) <- query(FN(() <- somenode(test(x)); ),
 qcount(n));
\end{verbatim}
where qcount/1 is defined as in Figure \ref{crewfig9}. Evaluating the
\verb|query()| term starts an embedded query corresponding to the first operand
and builds a query state ob ject representing the resulting first state (first
hit or failure). This ob ject then becomes the current object to which we try to
match qcount(n). It is the qnext() term therein that does the actual work. If
the query-state is a success state, we increment the count of hits thus far
(sofar), advance the embedded query, and recursively try to match a qcount term
to the new state. If the query-state is a failure, we unify the count of hits
thus far with the return variable.

To build a list of bindings for x corresponding to the
query hits, we can do
\begin{verbatim}
(list) <- query(FN((x) <- somenode(test(x)); ),
 qlist(list));
\end{verbatim}
which is essentially the same as before except that now
qlist(list) uses qget to examine the query state.
Since the embedded query has only one head variable
x, the qget term must likewise have at most one
operand.

Some care is required when using embedded queries
to phrase them so that the head variables will always
be bound to ob jects. qget() will in fact raise an error
if a head variable is not bound to an ob ject. This
requirement is crucial since, with a non-ob ject term,
there is no guarantee that said term will remain intact
when the embedded query backtracks to the next
state. Better to keep terms constructed by an embedded
query from polluting the outer world.

The mechanism is also somewhat impure in that
evaluating a qnext on a given query state ob ject essentially
destroys that ob ject. Subsequent attempts to
match additional terms against that query state will
raise an error since the state of a query is lost once we
advance it.

\secup %3

\secrel{Implementation}

astlog has been implemented as an interpreter in roughly 11,000 lines of \cpp\
for the core astlog interpreter and supporting utilities. Another 1100 lines
define the roughly 60 primitives and supporting structures to invoke the various
functions of the AST library. Coverage of the library API is in not entirely
complete, but it is sufficient to perform various interesting tasks:

\begin{itemize}
  \item 
Finding all instances of a simple assignment expression (=) occurring in any
boolean context, for example,
\begin{verbatim}
if ((major == SORTM)
|| (major == MEMORYM)
|| ((major == BUFFERM)
&& (minor = B_NOIO)))
\end{verbatim}
  \item 
Finding all instances of an equality-test (==) or dereference expression
occurring in any void context (i. e., where results are discarded); the converse
to the previous problem.
  \item 
Finding all case statement fall-throughs, i. e.,
where the preceding statement is not a break. 
  \item 
Finding various patterns of irreducible control-
ow in functions. 
  \item 
Obtaining all static call-graph edges. 
  \item 
Computing the McCabe cyclomatic complexity \cite{McC76} of a function. Our code
to do so looks like
\begin{verbatim}
mccabe(n) <- query(
FN(()<- somenode(
op(or(#IF,#FOR,#DO,
#WHILE,#CASE,
#?,#||,#&&)));)
qcount(minus(n,1))
);
\end{verbatim}
which might be compared with the 17-line version in Aria \cite{DR96}.
Admittedly, fairness would probably entail including the definitions of somenode
and qcount as well.
  \item 
Finding gaps (unused space due to alignment rules) in structure definitions;
this is a matter of traversing \ci\ type structures rather than asts.
\end{itemize}

A typical running time (on a 200MHz Pentium P6 with
64meg of RAM) for a one-pass search that evaluates
a simple predicate on every ast node in Microsoft
\prog{SQLserver} (roughly 450,000 lines, 4300 functions) is
roughly 10 minutes, of which 7.5 minutes are taken up
by the ast library building the actual trees. For Microsoft
Word (roughly 2,000,000 lines) the corresponding
times are 45-60 minutes of which about 30 minutes
is taken up by the tree builder.

Though this dreadfully slow in comparison with
grep, these times are arguably acceptable in comparison
with the times taken by the actual compiler |
what one might expect for a tool that requires the use
of compiler's data structures. One is, of course, free
to write arbitrarily non-linear programs in astlog, so
there are no guarantees. In any case we would doubtless
see a certain amount of speedup if we actually were
to attempt some kind of compilation of the astlog
code.

\secrel{Conclusions and Future Work}

We have described a language for doing syntax-level
analysis for C/C++ programs, though the core language
is, in fact, adaptable to many other kinds of
structures. As with previous such tools, the utility
to users who are thus no longer required to write
their own parse/semantic-analysis phase is apparent.
The contribution here is a pattern language sufficiently
powerful to provide traversal possibilites beyond what
is naturally available in prior awk-like frameworks
while avoiding some of the ineficiencies of importing
the entire program structure into a logical inference
engine. The Pan work \cite{BGV90} stressed the need to
partition code and data; this we have done in a rather
straightforward way. The surprise is that the \prolog\
with-an-ambient-current-object model turns out to be
so well suited to analyzing treelike structures.

To be sure, there are various rough edges:

\begin{enumerate}
  \item 
As already noted, embedded queries are slightly
unsafe; there may exist a more robust set of primitives
to use. Some form of type inference to detect
unsafe uses of qnext may also be worth considering.
More generally, there is the issue of typing
of astlog expressions to reduce the incidence of
unbound variables or ob jects of the wrong type
appearing as operands where ob ject-references of
a particular type are required.

\item
Occasionally, we run up against the generally
cumbersome nature of arithmetic in Prolog, which
is arguably worse in astlog. The ``inside-out
functional'' nature of astlog may be good for
ast patterns, but it can make arithmetic operations
like
\begin{verbatim}
with(n; divide(minus(x; 1); 2))
\end{verbatim}
downright unreadable. Algebraic syntax could help, e. g.,
\begin{verbatim}
with(n; (x - 1)=2) 
\end{verbatim}
but even so, one must stare at this pretty hard to
realize that n is being multiplied by 2 and then
incremented by 1.

One possibility is to complicate the language by
introducing actual ``forward'' functional operator
definitions. For example, with such forward operators
for addition and multiplication, one could
then write
\begin{verbatim}
with(2  n + 1; x)
\end{verbatim}
where the appearance of the + (plus) term in
a slot normally requiring an ob ject reference in- vokes the forward
return-value-to-context definition of the operator + to sum its operands
rather than the usual ``backward'' return-valueto-operand
definition (see Figure 2) in which one
operand is treated as a predicate.

\item
Though there is a surprising amount of mileage to
be had via instantiating terms with unbound variables
in them, there are those occasions when a
genuinely mutable data structure is required. Fortunately,
given the strong partition between the
script/database and the ob jects, having mutable
ob jects exist and primitives that side-effect them
when they match would not disrupt astlog's execution
model.

\item
Currently, new primitives need to be manually
written. Given the current collection of macros
available, this is not actually an arduous task.
Still, while language-independence was not one
of our priorities, given that the core language is
rather language-independent anyway, one would
hope for a more automatic means of adapting
astlog to work with other language parsers, perhaps
by adapting GENII \cite{Dev92} or some similar
tool to generate code for the basic primitive predicate
operators for a fresh language.
 
\end{enumerate}

\secrel{Acknowledgements}

ASTLOG would not have been possible without the existence
of an ast library for C/C++ implemented by
the members of Program Analysis group at Microsoft
Research, particularly Linda O'Gara, David Gay, Erik
Ruf and Bjarne Steensgaarde. I would also like to
thank Bruce Duba, Michael Ernst, Chris Ramming,
and the conference reviewers for much useful commentary
and discussion.

\secly{References}

\begin{description}
\item[AKW86] A. V. Aho, B. W. Kernighan, and P. J.
Weinberger. The AWK Programming Language.
Addison Wesley, Reading, MA,
1986.
\item[BCD88] P. Borras, D. Clement, Th. Despeyroux,
J. Incerpi, G. Kahn, B. Lang, and V. Pascual.
Centaur: The system. In Proceedings
of the SIGSOFT/SIGPLAN Software
Engineering Symposium on Practical Software
Development Environments, Boston,
MA, 1988.
\item[BGV90] Robert A. Ballance, Susan L. Graham,
and Michael L. Van De Vanter. The
pan language-based editing system for integrated
development environments. In Proceedings
of the 4th ACM SIGSOFT Symposium
on Software Development Environments,
pages 77..93, Irvine, CA, 1990.
\item[CMR92] Mariano Consens, Alberto Mendelzon, and
Arthur Ryman. Visualizing and querying
software structures. In Proceedings of the
Fourteenth International ACM Conference
on Software Engineering, pages 138..156,
1992.
\item[Dev92] Premkumar T. Devanbu. Genoa - a
customizable, language-and-front-end independent
code analyzer. In Proceedings of
the Fourteenth International ACM Conference
on Software Engineering, pages 307..319. ACM Press, 1992.
\item[DR96] Premkumar T. Devanbu and David S.
Rosenblum. Generating testing and analysis
tools with aria. ACM Transactions
on Software Engineering and Methodology, 5(1):42..62, January 1996.
\item[GA96] William G. Griswold and Darren C. Atkinson.
Fast, exible syntactic pattern matching
and processing. In Proceedings of the
IEEE Workshop on Program Comprehension.
ACM Press, 1996.
\item[LR95] David A. Ladd and J. Christopher Ramming.
A*: A language for implementing
language processors. IEEE Transactions
on Software Engineering, 21(11):894..901,
November 1995.
\item[McC76] T. McCabe. A complexity measure.
IEEE Transactions on Software Engineering,
2(4):308..320, December 1976.
\item[SS86] Leon Sterling and Ehud Shapiro. The Art
of Prolog: Advanced Programming Techniques.
MIT Press series in logic programming.
The MIT Press, Cambridge, MA,
1986.
\end{description}

\secly{Appendix}

For those who would prefer to see a slightly more formal
description, we include a brief outline of an operational
semantics for astlog in Figure 10, one that
bears some resemblance to the actual implementation.

For any given term that is not an ob ject reference,
one may imagine there being numerous instances of
that term in existence at any given time. We differentiate
the various instances by assigning each a unique
frame identifier (f ) which is only significant for its
identity. A variable v occurring within a given term t
may, for a particular instance hf ; \verb|[[t]]i| of that term,
be bound to some ob ject o or other term instance
\verb|hf 0 ; [[t|
\verb|0 ]]i|, this being indicated by having a binding,
i.e., one of \verb|hf ; [[v]]i fi o or hf ; [[v]]ifihf 0 ; [[t|
\verb|0 ]]i| present
in the current binding stack, which in turn is nothing
more than a list of bindings. The semantic function
\verb|vlookup(B ; hf ; [[t]]i)| returns
\begin{itemize}
  \item 
\verb| hf ; [[t]]i| itself if t is not a variable. 
  \item 
 ? if the variable t is not bound in B. 
  \item 
 o if hf ; \verb|[[t]]i | o is in B
  \item 
 \verb|vlookup(B ; hf 0 ; [[t|
\verb|0 ]]i) if hf ; [[t]]iffhf 0 ; [[t|
\verb|0]]i | is in B.
 \end{itemize}
 
 At any given time, the full state of our abstract machine
is described by a failure of the form B ` C :: F
which consists of

\begin{itemize}
  \item the current binding stack B,
  \item the current continuation C = (o; f ; g; C0), which
in turn consists of a current ob ject o, a current
frame identifier f , a current goal, usually a term,
but this can also be one of the auxiliary goals
``apply(\ldots)'' or ``cut(\ldots),'' and finally another
continuation C0 to which we advance if the goal
succeeds
\item the next failure F , to which we advance if the
current goal fails.
\end{itemize}

Note that unlike the case where the goal succeeds, failure
may involve undoing one or more bindings; thus,
a failure (F ) contains its own binding stack (a subset
of B) whereas the continuations (C, C0) do not.

The bottom half of Figure 10 (partially) defines a
transition relation between states of the abstract machine.
Given an initial current ob ject o and a query
[[query]] with n head variables, we take the initial state
to be

\verb|F0 = [] ` (o; f0; apply(f0; [[query]]; [[v1;:::; vn]]); yes) :: no|
If there is a sequence of transitions
\verb|F0 !|
\verb|B1 ` yes :: F\verb|
then we have a hit and the various query head bindings
are available as \verb|vlookup(B1; hf0; [[vi ]]i) for i = 1 :::n.| Likewise, if
\verb|Fk !|
\verb|Bk ` yes :: Fk+1|
then we have a |(k + 1)th| hit.

When we have \verb|a(k + 1)th| hit.
The semantic function
\verb|mgu(B; f; [[t1;:::;tn]]; f 0 ; [[t\verb|
\verb|01;:::;t0n]])|
returns an augmented binding stack that includes B
together with those additional bindings that make up
the most general unifier of the respective term instances
\verb|hf ; [[t1]]i with hf 0 ; [[t|
\verb|01]]i, etc:::| . If there is no
most general unifier, \verb|mgu()| returns \verb|ufail|.

In the actual implementation, because the script is
unified, we may precompute at load time mgus of all
pairs of same-operator-and-arity compound terms occurring
in the script, making clause invocation no more
expensive than a function call in many cases. We also
omit the ``occurs check'' \cite{SS86} for the run-time portion
of unification (i.e., where we're transitively following
variable bindings), with the usual increase in
speed and infinite-loop risk. Thus far, unification has
played a somewhat smaller role in astlog scripts than
expected, so there's some question whether we need to
be doing even this much.

As noted above ob jects only unify with equal objects.
The idea of allowing an ob ject to unify with
a compound predicate term that matches it has been
considered, but rejected due to the significant complications
it would introduce. Also, once one has subgoals
being attempted during the course of unification, the
user's control over evaluation order is drastically reduced,
something to be avoided if one is interested in
having users being able to write efficient scripts.

\subsecly{Figure 10: Outline of astlog Operational Semantics}\label{crewfig10}

\secup %crew